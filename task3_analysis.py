import pandas as pd
import numpy as np
import akshare as ak
import requests
import json
from datetime import datetime, timedelta
import warnings
from typing import Dict, List, Optional, Any

warnings.filterwarnings('ignore')


# ==================== æ•°æ®å±‚ ====================
class Task3DataManager:
    """
    æ•°æ®ç®¡ç†å±‚ï¼šå¤„ç†ä»»åŠ¡ä¸‰æ‰€éœ€çš„æ‰€æœ‰æ•°æ®
    """

    def __init__(self, task2_analyzer, returns_data):
        self.task2_analyzer = task2_analyzer
        self.returns_data = returns_data
        self.base_sectors = task2_analyzer.sectors
        self.base_factors = task2_analyzer.belonging_factors

    def validate_input_data(self):
        """éªŒè¯è¾“å…¥æ•°æ®å®Œæ•´æ€§"""
        if not self.base_sectors:
            raise ValueError("âŒ ä»»åŠ¡äºŒæœªå‘çŽ°æœ‰æ•ˆæ¿å—")
        if self.returns_data.empty:
            raise ValueError("âŒ æ”¶ç›ŠçŽ‡æ•°æ®ä¸ºç©º")

        print(f"âœ… æ•°æ®éªŒè¯é€šè¿‡")
        print(f"   æ¿å—æ•°é‡: {len(self.base_sectors)}")
        print(f"   è‚¡ç¥¨æ•°é‡: {sum(len(stocks) for stocks in self.base_sectors.values())}")
        print(f"   æ•°æ®æœŸé—´: {self.returns_data.index[0]} åˆ° {self.returns_data.index[-1]}")

    def get_time_periods(self, window_size: int, step_size: int) -> List[Dict]:
        """ç”Ÿæˆåˆ†æžæ—¶é—´çª—å£"""
        dates = self.returns_data.index
        periods = []

        for start_idx in range(0, len(dates) - window_size, step_size):
            end_idx = start_idx + window_size
            period_label = f"{dates[start_idx].strftime('%Y-%m-%d')}_to_{dates[end_idx].strftime('%Y-%m-%d')}"
            periods.append({
                'label': period_label,
                'start_idx': start_idx,
                'end_idx': end_idx,
                'start_date': dates[start_idx],
                'end_date': dates[end_idx]
            })

        print(f"   ç”Ÿæˆ {len(periods)} ä¸ªåˆ†æžæ—¶é—´æ®µ")
        return periods


# ==================== äº‹ä»¶æ•°æ®å±‚ ====================
class EventDataCollector:
    """
    äº‹ä»¶æ•°æ®æ”¶é›†å™¨ - åŸºäºŽçœŸå®žæ•°æ®æº
    """

    def __init__(self):
        self.cache = {}  # ç®€å•ç¼“å­˜é¿å…é‡å¤è¯·æ±‚

    def get_stock_events(self, stock_code: str, start_date: str, end_date: str) -> List[Dict]:
        """
        èŽ·å–è‚¡ç¥¨ç›¸å…³äº‹ä»¶ï¼ˆè´¢æŠ¥ã€å…¬å‘Šã€æ–°é—»ï¼‰
        """
        events = []

        try:
            # 1. èŽ·å–è´¢æŠ¥æ•°æ®
            earnings_events = self._get_earnings_events(stock_code, start_date, end_date)
            events.extend(earnings_events)

            # 2. èŽ·å–å…¬å¸å…¬å‘Š
            announcement_events = self._get_announcement_events(stock_code, start_date, end_date)
            events.extend(announcement_events)

            # 3. èŽ·å–æ–°é—»æ•°æ®
            news_events = self._get_news_events(stock_code, start_date, end_date)
            events.extend(news_events)

        except Exception as e:
            print(f"âš ï¸ èŽ·å– {stock_code} äº‹ä»¶æ•°æ®å¤±è´¥: {e}")

        # æŒ‰æ—¶é—´æŽ’åºå¹¶åŽ»é‡
        events = self._deduplicate_events(events)
        events.sort(key=lambda x: x.get('event_date', ''), reverse=True)

        return events[:15]  # è¿”å›žæœ€è¿‘15ä¸ªäº‹ä»¶

    # åœ¨task3_analysis.pyä¸­æ”¹è¿›è´¢æŠ¥æ•°æ®èŽ·å–æ–¹æ³•
    def _get_earnings_events(self, stock_code: str, start_date: str, end_date: str) -> List[Dict]:
        """èŽ·å–è´¢æŠ¥äº‹ä»¶ - ä¼˜åŒ–æ—¥æœŸå¤„ç†å’Œæ•°æ®æå–"""
        events = []
        try:
            # ä½¿ç”¨AKShareèŽ·å–è´¢åŠ¡æ•°æ®ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰
            # å°è¯•èŽ·å–æœ€æ–°çš„è´¢æŠ¥æ—¥æœŸæ•°æ®
            if stock_code.endswith('.SH'):
                symbol = f"sh{stock_code[:6]}"
            elif stock_code.endswith('.SZ'):
                symbol = f"sz{stock_code[:6]}"
            else:
                symbol = stock_code

            # å°è¯•èŽ·å–ä¸šç»©é¢„å‘Šæ•°æ®ï¼ˆæ›´ç›¸å…³çš„è´¢æŠ¥äº‹ä»¶ï¼‰
            try:
                forecast_df = ak.stock_forecast_report(symbol=symbol)
                if not forecast_df.empty:
                    for _, row in forecast_df.iterrows():
                        # æå–å®žé™…å…¬å‘Šæ—¥æœŸ
                        event_date = row.get('ann_date', datetime.now().strftime('%Y-%m-%d'))
                        if isinstance(event_date, pd.Timestamp):
                            event_date = event_date.strftime('%Y-%m-%d')

                        # ç¡®å®šå½±å“ç¨‹åº¦
                        if 'é¢„å¢ž' in row.get('content', ''):
                            impact = 'positive'
                        elif 'é¢„å‡' in row.get('content', ''):
                            impact = 'negative'
                        else:
                            impact = 'neutral'

                        event = {
                            'event_date': event_date,
                            'event_type': 'ä¸šç»©é¢„å‘Š',
                            'title': f"{row.get('title', 'ä¸šç»©é¢„å‘Š')}",
                            'content': row.get('content', ''),
                            'impact': impact,
                            'source': 'AKShare-ä¸šç»©é¢„å‘Š',
                            'stock_code': stock_code
                        }
                        events.append(event)
            except:
                pass  # è¯¥æŽ¥å£å¯èƒ½ä¸é€‚ç”¨äºŽæ‰€æœ‰è‚¡ç¥¨ï¼Œå¤±è´¥æ—¶è·³è¿‡

            # è¡¥å……èŽ·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®
            stock_individual_info_em_df = ak.stock_individual_info_em(symbol=symbol)
            if not stock_individual_info_em_df.empty:
                # æå–æœ€è¿‘ä¸€æ¬¡è´¢æŠ¥æ—¥æœŸ
                latest_finance_date = None
                if 'å‘å¸ƒæ—¥æœŸ' in stock_individual_info_em_df.columns:
                    date_cols = stock_individual_info_em_df['å‘å¸ƒæ—¥æœŸ'].dropna()
                    if not date_cols.empty:
                        latest_finance_date = date_cols.iloc[0]
                        if isinstance(latest_finance_date, pd.Timestamp):
                            latest_finance_date = latest_finance_date.strftime('%Y-%m-%d')

                for _, row in stock_individual_info_em_df.iterrows():
                    event = {
                        'event_date': latest_finance_date or datetime.now().strftime('%Y-%m-%d'),
                        'event_type': 'è´¢åŠ¡æŒ‡æ ‡',
                        'title': f"{row.get('item', 'è´¢åŠ¡æŒ‡æ ‡')}",
                        'content': str(row.to_dict()),
                        'impact': 'neutral',
                        'source': 'AKShare-è´¢åŠ¡æŒ‡æ ‡',
                        'stock_code': stock_code
                    }
                    events.append(event)

        except Exception as e:
            print(f"èŽ·å–è´¢æŠ¥æ•°æ®å¤±è´¥ {stock_code}: {e}")

        return events

    def _get_announcement_events(self, stock_code: str, start_date: str, end_date: str) -> List[Dict]:
        """èŽ·å–å…¬å¸å…¬å‘Š"""
        events = []
        try:
            # ä½¿ç”¨AKShareèŽ·å–æ–°é—»å…¬å‘Š
            stock_news_em_df = ak.stock_news_em(symbol=stock_code)
            if not stock_news_em_df.empty:
                for _, row in stock_news_em_df.iterrows():
                    event = {
                        'event_date': row.get('å‘å¸ƒæ—¶é—´', datetime.now().strftime('%Y-%m-%d')),
                        'event_type': 'å…¬å¸å…¬å‘Š',
                        'title': row.get('æ ‡é¢˜', ''),
                        'content': row.get('å†…å®¹', ''),
                        'impact': self._assess_announcement_impact(row.get('æ ‡é¢˜', '')),
                        'source': 'AKShare',
                        'stock_code': stock_code
                    }
                    events.append(event)

        except Exception as e:
            print(f"èŽ·å–å…¬å‘Šæ•°æ®å¤±è´¥ {stock_code}: {e}")

        return events

    def _get_news_events(self, stock_code: str, start_date: str, end_date: str) -> List[Dict]:
        """èŽ·å–æ–°é—»äº‹ä»¶"""
        events = []
        try:
            # ä½¿ç”¨AKShareèŽ·å–ä¸ªè‚¡æ–°é—»
            stock_news_em_df = ak.stock_news_em(symbol=stock_code)
            if not stock_news_em_df.empty:
                for _, row in stock_news_em_df.iterrows():
                    event = {
                        'event_date': row.get('å‘å¸ƒæ—¶é—´', datetime.now().strftime('%Y-%m-%d')),
                        'event_type': 'å¸‚åœºæ–°é—»',
                        'title': row.get('æ ‡é¢˜', ''),
                        'content': row.get('å†…å®¹', ''),
                        'impact': self._assess_news_impact(row.get('æ ‡é¢˜', '')),
                        'source': 'AKShare',
                        'stock_code': stock_code
                    }
                    events.append(event)

        except Exception as e:
            print(f"èŽ·å–æ–°é—»æ•°æ®å¤±è´¥ {stock_code}: {e}")

        return events

    def _assess_announcement_impact(self, title: str) -> str:
        """è¯„ä¼°å…¬å‘Šå½±å“"""
        positive_keywords = ['åˆ©å¥½', 'å¢žé•¿', 'ç›ˆåˆ©', 'åˆä½œ', 'è®¢å•', 'çªç ´', 'æ‰©å¼ ', 'æ”¶è´­', 'ä¸­æ ‡']
        negative_keywords = ['äºæŸ', 'ä¸‹æ»‘', 'é£Žé™©', 'è¯‰è®¼', 'è­¦ç¤º', 'é€€å¸‚', 'å‡æŒ', 'è¿è§„']

        title_lower = title.lower()

        positive_count = sum(1 for keyword in positive_keywords if keyword in title_lower)
        negative_count = sum(1 for keyword in negative_keywords if keyword in title_lower)

        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'

    def _assess_news_impact(self, title: str) -> str:
        """è¯„ä¼°æ–°é—»å½±å“"""
        return self._assess_announcement_impact(title)

    def _deduplicate_events(self, events: List[Dict]) -> List[Dict]:
        """åŽ»é‡äº‹ä»¶"""
        seen = set()
        unique_events = []

        for event in events:
            event_key = f"{event.get('event_date')}_{event.get('title')}"
            if event_key not in seen:
                seen.add(event_key)
                unique_events.append(event)

        return unique_events


# ==================== åˆ†æžå±‚ ====================
class ChangeDetector:
    """
    å˜åŒ–æ£€æµ‹å±‚ï¼šè¯†åˆ«å½’å±žå› æ•°çš„æ˜¾è‘—å˜åŒ–
    """

    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.belonging_changes = {}

    def detect_changes_multi_period(self, window_size: int = 60, step_size: int = 30) -> Dict:
        """
        å¤šæ—¶æœŸå˜åŒ–æ£€æµ‹
        """
        print("ðŸ” å¼€å§‹å¤šæ—¶æœŸå˜åŒ–æ£€æµ‹...")

        periods = self.data_manager.get_time_periods(window_size, step_size)
        base_factors = self.data_manager.base_factors

        total_analyses = 0

        for sector_id, stocks in self.data_manager.base_sectors.items():
            print(f"   åˆ†æžæ¿å— {sector_id} ({len(stocks)}åªè‚¡ç¥¨)...")
            sector_changes = self._analyze_sector_changes(sector_id, stocks, periods, base_factors)
            self.belonging_changes[sector_id] = sector_changes
            total_analyses += len(sector_changes)

        print(f"âœ… å˜åŒ–æ£€æµ‹å®Œæˆï¼Œå…±è¿›è¡Œ {total_analyses} ä¸ªæ—¶é—´æ®µåˆ†æž")
        return self.belonging_changes

    def _analyze_sector_changes(self, sector_id: str, stocks: List[str], periods: List[Dict],
                                base_factors: Dict) -> Dict:
        """åˆ†æžå•ä¸ªæ¿å—çš„å˜åŒ–"""
        sector_changes = {}

        for period in periods:
            # è®¡ç®—å½“å‰çª—å£çš„å½’å±žå› æ•°
            window_data = self.data_manager.returns_data.iloc[period['start_idx']:period['end_idx']]
            current_factors = self._calculate_period_factors(window_data, stocks)

            if current_factors:
                changes = self._compute_factor_changes(
                    base_factors.get(sector_id, {}),
                    current_factors
                )
                sector_changes[period['label']] = changes

        return sector_changes

    def _calculate_period_factors(self, period_returns: pd.DataFrame, stocks: List[str]) -> Dict[str, float]:
        """è®¡ç®—ç‰¹å®šæ—¶æœŸçš„å½’å±žå› æ•°"""
        factors = {}
        available_stocks = [s for s in stocks if s in period_returns.columns]

        if len(available_stocks) < 3:
            return factors

        try:
            sector_benchmark = period_returns[available_stocks].mean(axis=1)

            for stock in available_stocks:
                try:
                    correlation = np.corrcoef(period_returns[stock], sector_benchmark)[0, 1]
                    if not np.isnan(correlation):
                        factor = 0.3 + 0.6 * (correlation + 1) / 2
                        factors[stock] = min(0.9, max(0.3, factor))
                except:
                    continue

        except Exception as e:
            print(f"      è®¡ç®—å› æ•°å‡ºé”™: {e}")

        return factors

    def _compute_factor_changes(self, base_factors: Dict, current_factors: Dict) -> Dict:
        """è®¡ç®—å½’å±žå› æ•°å˜åŒ–"""
        changes = {}

        for stock, current_factor in current_factors.items():
            base_factor = base_factors.get(stock, 0.5)
            change = current_factor - base_factor

            changes[stock] = {
                'stock': stock,
                'base_factor': base_factor,
                'current_factor': current_factor,
                'change': change,
                'change_pct': (change / base_factor) * 100 if base_factor > 0 else 0,
                'significance': self._assess_significance(change),
                'direction': 'ä¸Šå‡' if change > 0 else 'ä¸‹é™',
                'magnitude': abs(change)
            }

        return changes

    def _assess_significance(self, change: float) -> str:
        """è¯„ä¼°å˜åŒ–æ˜¾è‘—æ€§"""
        abs_change = abs(change)
        if abs_change > 0.2:
            return 'high'
        elif abs_change > 0.1:
            return 'medium'
        else:
            return 'low'


# ==================== å½’å› å¼•æ“Žå±‚ ====================
class EventDrivenAttributionEngine:
    """
    äº‹ä»¶é©±åŠ¨çš„å½’å› å¼•æ“Ž - åŸºäºŽçœŸå®žäº‹ä»¶æ•°æ®
    """

    def __init__(self):
        self.event_collector = EventDataCollector()
        self.reason_templates = self._initialize_reason_templates()

    def _initialize_reason_templates(self) -> Dict:
        """åˆå§‹åŒ–å½’å› åŽŸå› æ¨¡æ¿"""
        return {
            'positive_high': [
                "è´¢æŠ¥ä¸šç»©è¶…é¢„æœŸï¼Œç›ˆåˆ©å¤§å¹…å¢žé•¿{change_pct:.1f}%",
                "èŽ·å¾—é‡å¤§æˆ˜ç•¥è®¢å•ï¼Œä¸šåŠ¡å‰æ™¯æ˜¾è‘—æ”¹å–„",
                "æŠ€æœ¯åˆ›æ–°å–å¾—çªç ´ï¼Œè¡Œä¸šç«žäº‰åŠ›å¤§å¹…æå‡",
                "è¡Œä¸šæ”¿ç­–é‡å¤§åˆ©å¥½ï¼Œå…¬å¸å……åˆ†å—ç›Š"
            ],
            'positive_medium': [
                "ç»è¥çŠ¶å†µæŒç»­æ”¹å–„ï¼Œå¸‚åœºä»½é¢ç¨³æ­¥æ‰©å¤§",
                "æˆæœ¬æŽ§åˆ¶æˆæ•ˆæ˜¾è‘—ï¼Œåˆ©æ¶¦çŽ‡æ˜Žæ˜¾æå‡",
                "æ–°äº§å“æˆåŠŸä¸Šå¸‚ï¼Œæ”¶å…¥æ¥æºæ›´åŠ å¤šå…ƒåŒ–",
                "ç®¡ç†æ•ˆçŽ‡æå‡ï¼Œè¿è¥æˆæœ¬ä¸‹é™"
            ],
            'negative_high': [
                "è´¢æŠ¥ä¸šç»©ä¸åŠé¢„æœŸï¼Œç›ˆåˆ©å¤§å¹…ä¸‹æ»‘{change_pct:.1f}%",
                "é‡è¦é¡¹ç›®é­é‡é‡å¤§æŒ«æŠ˜æˆ–å–æ¶ˆ",
                "è¡Œä¸šç›‘ç®¡æ”¿ç­–æ”¶ç´§ï¼Œç»è¥å—åˆ°ä¸¥æ ¼é™åˆ¶",
                "å¸‚åœºç«žäº‰æ¿€çƒˆï¼Œå¸‚åœºä»½é¢ä¸¥é‡æµå¤±"
            ],
            'negative_medium': [
                "åŽŸææ–™æˆæœ¬å¤§å¹…ä¸Šå‡ï¼Œåˆ©æ¶¦çŽ‡å—åˆ°æŒ¤åŽ‹",
                "å¸‚åœºéœ€æ±‚å‡ºçŽ°å­£èŠ‚æ€§æ³¢åŠ¨",
                "æ±‡çŽ‡æ³¢åŠ¨å¯¹æµ·å¤–ä¸šåŠ¡é€ æˆè´Ÿé¢å½±å“",
                "è¡Œä¸šå‘¨æœŸæ€§è°ƒæ•´å½±å“ä¸šç»©è¡¨çŽ°"
            ]
        }

    def perform_attribution_analysis(self, significant_changes: Dict) -> Dict:
        """
        æ‰§è¡Œå½’å› åˆ†æž
        """
        print("ðŸ§  æ‰§è¡Œäº‹ä»¶é©±åŠ¨çš„å½’å› åˆ†æž...")

        attribution_results = {}
        total_attributions = 0

        for sector_id, period_changes in significant_changes.items():
            print(f"  åˆ†æžæ¿å— {sector_id} çš„å½’å› ...")
            sector_attributions = {}

            for period, changes in period_changes.items():
                period_attributions = {}

                for stock, change_info in changes.items():
                    attribution = self._analyze_single_change_with_events(stock, period, change_info)
                    period_attributions[stock] = attribution
                    total_attributions += 1

                if period_attributions:
                    sector_attributions[period] = period_attributions

            if sector_attributions:
                attribution_results[sector_id] = sector_attributions

        print(f"âœ… å½’å› åˆ†æžå®Œæˆï¼Œå…±ç”Ÿæˆ {total_attributions} ä¸ªå½’å› åˆ†æž")
        return attribution_results

    def _analyze_single_change_with_events(self, stock: str, period: str, change_info: Dict) -> Dict:
        """åŸºäºŽäº‹ä»¶åˆ†æžå•ä¸ªå˜åŒ–"""
        # è§£æžæ—¶é—´æ®µ
        start_date, end_date = self._parse_period(period)

        # æ”¶é›†ç›¸å…³äº‹ä»¶
        events = self.event_collector.get_stock_events(stock, start_date, end_date)

        if events:
            # åŸºäºŽçœŸå®žäº‹ä»¶è¿›è¡Œå½’å› 
            return self._event_based_attribution(stock, period, change_info, events)
        else:
            # ä½¿ç”¨è§„åˆ™å¼•æ“Žå½’å› 
            return self._rule_based_attribution(stock, period, change_info)

    def _event_based_attribution(self, stock: str, period: str, change_info: Dict, events: List[Dict]) -> Dict:
        """åŸºäºŽçœŸå®žäº‹ä»¶çš„å½’å› """
        # åˆ†æžäº‹ä»¶å½±å“
        significant_events = [e for e in events if e['impact'] in ['positive', 'negative']]

        if significant_events:
            reasons = []
            for event in significant_events[:2]:  # å–æœ€é‡è¦çš„ä¸¤ä¸ªäº‹ä»¶
                reason = f"{event['event_type']}: {event['title']}"
                reasons.append(reason)

            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = 'é«˜' if len(significant_events) >= 2 else 'ä¸­'

            attribution = {
                'stock': stock,
                'period': period,
                'factor_change': change_info['change'],
                'change_direction': change_info['direction'],
                'change_magnitude': change_info['significance'],
                'event_based': True,
                'events_count': len(significant_events),
                'total_events': len(events),
                'possible_reasons': reasons,
                'confidence': confidence,
                'analysis_method': 'äº‹ä»¶é©±åŠ¨å½’å› ',
                'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        else:
            attribution = self._rule_based_attribution(stock, period, change_info)
            attribution['event_based'] = False
            attribution['events_count'] = len(events)

        return attribution

    def _rule_based_attribution(self, stock: str, period: str, change_info: Dict) -> Dict:
        """åŸºäºŽè§„åˆ™çš„å½’å› """
        change = change_info['change']
        significance = change_info['significance']
        direction = change_info['direction']

        # ç¡®å®šå½’å› ç±»åž‹
        if direction == 'ä¸Šå‡':
            if significance == 'high':
                reason_key = 'positive_high'
                confidence = 'é«˜'
            else:
                reason_key = 'positive_medium'
                confidence = 'ä¸­'
        else:
            if significance == 'high':
                reason_key = 'negative_high'
                confidence = 'é«˜'
            else:
                reason_key = 'negative_medium'
                confidence = 'ä¸­'

        # é€‰æ‹©åŽŸå› æ¨¡æ¿
        templates = self.reason_templates[reason_key]
        import random
        selected_reasons = random.sample(templates, min(2, len(templates)))

        # æ ¼å¼åŒ–åŽŸå› 
        formatted_reasons = []
        for reason in selected_reasons:
            formatted_reason = reason.format(change_pct=abs(change_info['change_pct']))
            formatted_reasons.append(formatted_reason)

        return {
            'stock': stock,
            'period': period,
            'factor_change': change,
            'change_direction': direction,
            'change_magnitude': significance,
            'event_based': False,
            'events_count': 0,
            'total_events': 0,
            'possible_reasons': formatted_reasons,
            'confidence': confidence,
            'analysis_method': 'è§„åˆ™å¼•æ“Žå½’å› ',
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

    def _parse_period(self, period_str: str) -> tuple:
        """è§£æžæ—¶é—´æ®µ"""
        try:
            parts = period_str.split('_to_')
            start_date = datetime.strptime(parts[0], '%Y-%m-%d')
            end_date = datetime.strptime(parts[1], '%Y-%m-%d')
            return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')
        except:
            # é»˜è®¤è¿”å›žæœ€è¿‘30å¤©
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')


# ==================== æŠ¥å‘Šç”Ÿæˆå±‚ ====================
class ComprehensiveReportGenerator:
    """
    ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨
    """

    def __init__(self, attribution_results: Dict):
        self.attribution_results = attribution_results

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\n" + "=" * 100)
        print("ðŸ“Š ä»»åŠ¡ä¸‰ï¼šå½’å±žå› æ•°å˜åŒ–å½’å› åˆ†æžç»¼åˆæŠ¥å‘Š")
        print("=" * 100)

        total_analyses = 0
        event_based_analyses = 0
        significant_analyses = 0
        positive_changes = 0
        negative_changes = 0

        # è¯¦ç»†åˆ†æžæŠ¥å‘Š
        for sector_id, period_attributions in self.attribution_results.items():
            print(f"\nðŸŽ¯ æ¿å— {sector_id}")
            print("=" * 80)

            sector_analyses = 0
            sector_event_based = 0

            for period, stock_attributions in period_attributions.items():
                print(f"\n  æ—¶é—´æ®µ: {period}")
                print("  " + "â”€" * 60)

                for stock, attribution in stock_attributions.items():
                    total_analyses += 1
                    sector_analyses += 1

                    if attribution['event_based']:
                        event_based_analyses += 1
                        sector_event_based += 1

                    if attribution['confidence'] in ['é«˜', 'ä¸­']:
                        significant_analyses += 1

                    if attribution['change_direction'] == 'ä¸Šå‡':
                        positive_changes += 1
                    else:
                        negative_changes += 1

                    self._print_detailed_attribution(attribution)

            # æ¿å—ç»Ÿè®¡
            if sector_analyses > 0:
                event_based_ratio = sector_event_based / sector_analyses
                print(f"\n  ðŸ“ˆ æ¿å—ç»Ÿè®¡: å…±{sector_analyses}ä¸ªåˆ†æž, "
                      f"äº‹ä»¶é©±åŠ¨{sector_event_based}ä¸ª({event_based_ratio:.1%})")

        # æ±‡æ€»ç»Ÿè®¡
        self._print_summary_statistics(
            total_analyses, event_based_analyses, significant_analyses,
            positive_changes, negative_changes
        )

    def _print_detailed_attribution(self, attribution: Dict):
        """æ‰“å°è¯¦ç»†å½’å› åˆ†æž"""
        # å›¾æ ‡é€‰æ‹©
        direction_icon = "ðŸ“ˆ" if attribution['change_direction'] == 'ä¸Šå‡' else "ðŸ“‰"
        confidence_icon = "ðŸ”¥" if attribution['confidence'] == 'é«˜' else "âš ï¸" if attribution[
                                                                                    'confidence'] == 'ä¸­' else "â„¹ï¸"
        method_icon = "ðŸŽ¯" if attribution['event_based'] else "âš™ï¸"

        print(f"  {direction_icon} {attribution['stock']}")
        print(f"    å˜åŒ–: {attribution['factor_change']:+.3f} ({attribution['change_direction']})")
        print(f"    ç¨‹åº¦: {attribution['change_magnitude']} | ç½®ä¿¡åº¦: {confidence_icon} {attribution['confidence']}")
        print(f"    æ–¹æ³•: {method_icon} {attribution['analysis_method']}")

        if attribution['event_based']:
            print(f"    äº‹ä»¶: å…±{attribution['total_events']}ä¸ª, æ˜¾è‘—{attribution['events_count']}ä¸ª")

        print(f"    å¯èƒ½åŽŸå› :")
        for i, reason in enumerate(attribution['possible_reasons'], 1):
            print(f"      {i}. {reason}")

        print(f"    åˆ†æžæ—¶é—´: {attribution['analysis_timestamp']}")
        print()

    def _print_summary_statistics(self, total_analyses: int, event_based_analyses: int,
                                  significant_analyses: int, positive_changes: int, negative_changes: int):
        """æ‰“å°æ±‡æ€»ç»Ÿè®¡"""
        print("\n" + "=" * 100)
        print("ðŸ“ˆ ç»¼åˆåˆ†æžç»Ÿè®¡")
        print("=" * 100)

        print(f"ðŸ“Š åŸºç¡€ç»Ÿè®¡:")
        print(f"   æ€»åˆ†æžæ¡ˆä¾‹: {total_analyses}")
        print(f"   æ˜¾è‘—å˜åŒ–æ¡ˆä¾‹: {significant_analyses}")
        print(f"   åˆ†æžè¦†ç›–çŽ‡: {significant_analyses / total_analyses * 100:.1f}%")

        print(f"\nðŸŽ¯ å½’å› æ–¹æ³•:")
        print(f"   äº‹ä»¶é©±åŠ¨åˆ†æž: {event_based_analyses}ä¸ª ({event_based_analyses / total_analyses * 100:.1f}%)")
        print(
            f"   è§„åˆ™å¼•æ“Žåˆ†æž: {total_analyses - event_based_analyses}ä¸ª ({(total_analyses - event_based_analyses) / total_analyses * 100:.1f}%)")

        print(f"\nðŸ“ˆ å˜åŒ–æ–¹å‘:")
        print(f"   ä¸Šå‡å˜åŒ–: {positive_changes}ä¸ª ({positive_changes / total_analyses * 100:.1f}%)")
        print(f"   ä¸‹é™å˜åŒ–: {negative_changes}ä¸ª ({negative_changes / total_analyses * 100:.1f}%)")
        print(f"   å‡€å˜åŒ–æ–¹å‘: {'ä¸Šå‡' if positive_changes > negative_changes else 'ä¸‹é™'}")
        print(f"   å˜åŒ–å¹³è¡¡åº¦: {(positive_changes - negative_changes) / total_analyses * 100:+.1f}%")

        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        confidence_dist = {'é«˜': 0, 'ä¸­': 0, 'ä½Ž': 0}
        for sector_attributions in self.attribution_results.values():
            for period_attributions in sector_attributions.values():
                for attribution in period_attributions.values():
                    confidence_dist[attribution['confidence']] += 1

        print(f"\nâœ… ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        for conf_level, count in confidence_dist.items():
            if total_analyses > 0:
                percentage = count / total_analyses * 100
                print(f"   {conf_level}ç½®ä¿¡åº¦: {count}ä¸ª ({percentage:.1f}%)")

    def save_detailed_results(self, filename: str = 'task3_detailed_results.csv'):
        """ä¿å­˜è¯¦ç»†ç»“æžœ"""
        results_data = []

        for sector_id, period_attributions in self.attribution_results.items():
            for period, stock_attributions in period_attributions.items():
                for stock, attribution in stock_attributions.items():
                    record = {
                        'sector_id': sector_id,
                        'analysis_period': period,
                        'stock_code': stock,
                        'factor_change': attribution['factor_change'],
                        'change_direction': attribution['change_direction'],
                        'change_magnitude': attribution['change_magnitude'],
                        'event_based': attribution['event_based'],
                        'events_count': attribution['events_count'],
                        'total_events': attribution['total_events'],
                        'confidence_level': attribution['confidence'],
                        'analysis_method': attribution['analysis_method'],
                        'possible_reason_1': attribution['possible_reasons'][0] if len(
                            attribution['possible_reasons']) > 0 else '',
                        'possible_reason_2': attribution['possible_reasons'][1] if len(
                            attribution['possible_reasons']) > 1 else '',
                        'possible_reason_3': attribution['possible_reasons'][2] if len(
                            attribution['possible_reasons']) > 2 else '',
                        'analysis_timestamp': attribution['analysis_timestamp']
                    }
                    results_data.append(record)

        df = pd.DataFrame(results_data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… è¯¦ç»†ç»“æžœå·²ä¿å­˜åˆ°: {filename}")
        return df

    def save_summary_report(self, filename: str = 'task3_summary_report.txt'):
        """ä¿å­˜æ–‡æœ¬æ‘˜è¦æŠ¥å‘Š"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("ä»»åŠ¡ä¸‰ï¼šå½’å±žå› æ•°å˜åŒ–å½’å› åˆ†æžæ‘˜è¦æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")

            total_analyses = 0
            for sector_id, period_attributions in self.attribution_results.items():
                f.write(f"æ¿å— {sector_id}:\n")
                for period, stock_attributions in period_attributions.items():
                    f.write(f"  æ—¶æœŸ {period}: {len(stock_attributions)} ä¸ªåˆ†æž\n")
                    total_analyses += len(stock_attributions)

            f.write(f"\næ€»åˆ†æžæ•°é‡: {total_analyses}\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        print(f"âœ… æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")


# ==================== ä¸»æŽ§åˆ¶å™¨ ====================
class Task3MainController:
    """
    ä»»åŠ¡ä¸‰ä¸»æŽ§åˆ¶å™¨
    """

    def __init__(self, task2_analyzer, returns_data):
        self.data_manager = Task3DataManager(task2_analyzer, returns_data)
        self.change_detector = ChangeDetector(self.data_manager)
        self.attribution_engine = EventDrivenAttributionEngine()
        self.report_generator = None

    def run_complete_analysis(self, window_size: int = 30, step_size: int = 15,
                              change_threshold: float = 0.08) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„ä»»åŠ¡ä¸‰åˆ†æž
        """
        print("ðŸš€ å¼€å§‹ä»»åŠ¡ä¸‰å®Œæ•´åˆ†æžæµç¨‹")
        print("=" * 60)
        print(f"åˆ†æžå‚æ•°: çª—å£{window_size}å¤©, æ­¥é•¿{step_size}å¤©, é˜ˆå€¼{change_threshold}")

        try:
            # 1. æ•°æ®éªŒè¯
            print("ðŸ“‹ æ­¥éª¤1: æ•°æ®éªŒè¯...")
            self.data_manager.validate_input_data()

            # 2. å˜åŒ–æ£€æµ‹
            print("\nðŸ” æ­¥éª¤2: å˜åŒ–æ£€æµ‹...")
            all_changes = self.change_detector.detect_changes_multi_period(
                window_size=window_size,
                step_size=step_size
            )

            # 3. è¯†åˆ«æ˜¾è‘—å˜åŒ–
            print("\nðŸŽ¯ æ­¥éª¤3: è¯†åˆ«æ˜¾è‘—å˜åŒ–...")
            significant_changes = self._filter_significant_changes(all_changes, change_threshold)

            if not significant_changes:
                print("âŒ æœªå‘çŽ°æ˜¾è‘—å˜åŒ–ï¼Œåˆ†æžç»ˆæ­¢")
                return {}

            # 4. å½’å› åˆ†æž
            print("\nðŸ§  æ­¥éª¤4: å½’å› åˆ†æž...")
            attribution_results = self.attribution_engine.perform_attribution_analysis(significant_changes)

            if not attribution_results:
                print("âŒ å½’å› åˆ†æžå¤±è´¥")
                return {}

            # 5. ç”ŸæˆæŠ¥å‘Š
            print("\nðŸ“Š æ­¥éª¤5: ç”ŸæˆæŠ¥å‘Š...")
            self.report_generator = ComprehensiveReportGenerator(attribution_results)
            self.report_generator.generate_comprehensive_report()

            # 6. ä¿å­˜ç»“æžœ
            print("\nðŸ’¾ æ­¥éª¤6: ä¿å­˜ç»“æžœ...")
            self.report_generator.save_detailed_results()
            self.report_generator.save_summary_report()

            print("\nðŸŽ‰ ä»»åŠ¡ä¸‰åˆ†æžå®Œæˆï¼")
            return attribution_results

        except Exception as e:
            print(f"âŒ åˆ†æžè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return {}

    def _filter_significant_changes(self, all_changes: Dict, threshold: float) -> Dict:
        """è¿‡æ»¤æ˜¾è‘—å˜åŒ–"""
        significant_changes = {}
        total_significant = 0

        for sector_id, period_changes in all_changes.items():
            sector_significant = {}

            for period, changes in period_changes.items():
                period_significant = {
                    stock: info for stock, info in changes.items()
                    if abs(info['change']) >= threshold
                }

                if period_significant:
                    sector_significant[period] = period_significant
                    total_significant += len(period_significant)

            if sector_significant:
                significant_changes[sector_id] = sector_significant

        print(f"âœ… å‘çŽ° {total_significant} ä¸ªæ˜¾è‘—å˜åŒ– (é˜ˆå€¼: {threshold})")
        return significant_changes


# ==================== ä½¿ç”¨æŽ¥å£ ====================
def run_complete_task3_analysis(task2_analyzer, returns_data, **kwargs):
    """
    ä»»åŠ¡ä¸‰å®Œæ•´åˆ†æžå…¥å£å‡½æ•°

    Parameters:
    - task2_analyzer: ä»»åŠ¡äºŒåˆ†æžå™¨å®žä¾‹
    - returns_data: æ”¶ç›ŠçŽ‡æ•°æ®
    - **kwargs: åˆ†æžå‚æ•°

    Returns:
    - å½’å› åˆ†æžç»“æžœ
    """
    # è®¾ç½®åˆ†æžå‚æ•°
    window_size = kwargs.get('window_size', 30)
    step_size = kwargs.get('step_size', 15)
    change_threshold = kwargs.get('change_threshold', 0.08)

    print(f"ðŸ”§ åˆ†æžå‚æ•°:")
    print(f"   çª—å£å¤§å°: {window_size}å¤©")
    print(f"   æ»‘åŠ¨æ­¥é•¿: {step_size}å¤©")
    print(f"   å˜åŒ–é˜ˆå€¼: {change_threshold}")

    # åˆ›å»ºæŽ§åˆ¶å™¨å¹¶è¿è¡Œåˆ†æž
    controller = Task3MainController(task2_analyzer, returns_data)
    results = controller.run_complete_analysis(
        window_size=window_size,
        step_size=step_size,
        change_threshold=change_threshold
    )

    return results


def debug_change_detection(task2_analyzer, returns_data):
    """
    è°ƒè¯•å˜åŒ–æ£€æµ‹è¿‡ç¨‹
    """
    print("=== å˜åŒ–æ£€æµ‹è°ƒè¯• ===")

    # æ£€æŸ¥ä»»åŠ¡äºŒç»“æžœ
    print(f"ä»»åŠ¡äºŒæ¿å—æ•°é‡: {len(task2_analyzer.sectors)}")
    for sector_id, stocks in task2_analyzer.sectors.items():
        print(f"  æ¿å— {sector_id}: {len(stocks)} åªè‚¡ç¥¨")

    # æ£€æŸ¥æ”¶ç›ŠçŽ‡æ•°æ®
    print(f"æ”¶ç›ŠçŽ‡æ•°æ®å½¢çŠ¶: {returns_data.shape}")
    print(f"æ•°æ®æœŸé—´: {returns_data.index[0]} åˆ° {returns_data.index[-1]}")

    # åˆ†æžåŸºç¡€å½’å±žå› æ•°åˆ†å¸ƒ
    print("\nå½’å±žå› æ•°åˆ†å¸ƒ:")
    all_factors = []
    for sector_id, factors in task2_analyzer.belonging_factors.items():
        sector_factors = list(factors.values())
        all_factors.extend(sector_factors)
        if sector_factors:
            print(
                f"  æ¿å— {sector_id}: å¹³å‡{np.mean(sector_factors):.3f}, èŒƒå›´[{min(sector_factors):.3f}, {max(sector_factors):.3f}]")

    if all_factors:
        print(f"æ€»ä½“: å¹³å‡{np.mean(all_factors):.3f}, æ ‡å‡†å·®{np.std(all_factors):.3f}")

    return len(all_factors) > 0


def main_task3_analysis(task2_analyzer, returns_data):
    return run_complete_task3_analysis(task2_analyzer, returns_data)